收 方就发出确认报 文 ， 并向发送方通知 当前的窗口大小。 此外 ， 发送方也不要发送太小的报
文 段 ， 而是把数据积累成足够大的报文 段 ， 或达到接收方缓存的空间的一 半 大小。

上 述两种方法可配合使用。 使得在发送方不发送很小的报 文 段的 同 时 ， 接 收方也不要

在 缓存 刚 刚有了 一点小的空间就 急 忙把这个很小的窗口大小信 息 通知给发送方。

5 . 8   TCP 的 拥 塞控制

一

5 . 8. 1  拥 塞控制 的

般 原 理

在 计算机网络中的链路容量（即 带 宽） 、 交换(cid:7188)点中的缓存和处理机等 ，

扫 一扫

寄恩畸启视 频讲解

都是网络的资源。 在某段时间，若对网络中某一 资源的需求超过 了 该资源所(cid:7126)
提供的可用 部分 ， 网 络的性(cid:7126)就要变坏。 这 种情况就叫作拥塞( conge s tion )。 可 以把出现网络拥
塞的条件写成如下的关系 式：

区 对 负 源的需求 ＞ 可用 资 掠

(5-7)

若 网 络中有许多资 源 同 时呈 现 供应 不 足 ， 网络的性(cid:7126)就要明显变 坏 ， 整个网络的吞 吐

量将 随输入负 荷的增大而下 降。

有人可(cid:7126)会说： “ 只 要任 意 增加一 些 资 源 ， 例如 ， 把(cid:7188)点缓存的存储 空 间 扩大 ， 或把链

路 更 换 为 更 高速率的链路 ， 或把(cid:7188) 点处理机的运算速度 提高 ， 就可 以 解决 网 络 拥 塞 的 问题。 ”
其 实不然。 这 是 因 为网络拥 塞是 一个非常复杂的问题。 简单地采用上述做法， 在许 多 情 况下 ，
不但 不(cid:7126)解决拥 塞问题 ， 而且还可(cid:7126)使网络的性(cid:7126)更坏。

网络 拥 塞往往是 由很多 因 素 引 起的。 例如 ， 当 某个(cid:7188)点缓存的容量 太 小 时 ， 到达该(cid:7192)

点的分 组 因 无存储 空 间 暂存而不 得 不 被丢弃。 现在设想将 该(cid:7188)点缓存的容量扩 展 到 非常大 ，

千 是 凡 到达该节点的分组均可在(cid:7188)点的缓存队 列 中排 队 ， 不 受任 何 限制。 由 千输 出 链 路的容

量 和处理机的处理速度并未 提高 ， 因此在这 队 列 中的绝大多数分组的排 队 等 待 时间将 会 大 大

增 加 ， 结 果 上层 软 件 只 好把它们进行重传（ 因 为早就超时 了 ）。 由此可见， 简单地扩 大 缓存

的存 储 空间同样 会造成网络 资 源的严重浪 费 ， 因 而解决不了 网络 拥 塞的问题。

又 如 ， 处理机处理的速率太低可(cid:7126) 引 起网络的拥 塞 。 简 单地将处理机的速率提高， 可
(cid:7126)会 使上述情况缓解 一 些 ， 但 往往又会将瓶颈转移到 其 他地方。 问题的实 质 往往是 整个 系 统
的各个部分不匹配。 只有所有的部分都平 衡 了 ， 问题才 会得到解决。

拥 塞 常常 趋 千 恶化 。 如果一个路由 器 没有足够的缓存空 间 ， 它就会丢弃 一 些 新 到 的分
组。 但 当 分组被 丢 弃 时 ， 发送这 一 分组的 源点就会重传这 一分组， 甚 (cid:7169)可(cid:7126)还要 重 传 多 次。
这样会 引 起更多的分组流入网络 和 被网络中的路由器丢弃。 可见拥 塞 引 起的重传 并 不 会 缓 解
网 络的拥 塞 ， 反 而 会加剧 网络的拥 塞。

拥 塞 控 制与流 量 控 制的关 系 密 切 ， 它 们 之间也存在着 一 些 差 别 。 所 谓 拥 塞控制 就 是 防
止过 多 的 数据注入到 网 络 中 ， 这样可 以使 网络 中 的 路 由 器 或链路不 (cid:7173)千过载。 拥 塞控制所要
做的都有 一个前提 ， 就是 网 络 (cid:7129) 够承 受 现 有 的 网络负荷。 拥 塞控 制是 一个全局 性 的 过程 ， 涉
及 所 有的主 机 、 所有的路由器 ， 以 及与降低网络传输性(cid:7126)有关的所有因 素。 但 TC P 连接的

端 点 只 要 迟 迟 不(cid:7126)收到对方的确认信 息 ， 就猜想 在 当 前网络中的某处很可(cid:7126)发生了拥 塞 ， 但

这 时却 无法知道 拥 塞 到 底发生在网络的何处， 也无法知道发生 拥 塞的具 体 原 因。 （ 是 访问某

个服务 器的通 信 量过大？ 还是 在 某个地区 出 现 (cid:7160) 然 灾 害？ ）

相 反 ， 流量控制 往 往 是 指 点 对 点 通 信 量 的 控 制 ， 是个端 到 端 的问题 （ 接收 端 控 制发送

•  238  •

端 ） 。 流量控制所要做的就是 抑制发送端发送数据的速率 ， 以便接收端 来 得及接收。

可 以用一个简单例子说明这种 区 别 。 设某个光纤网络的链路传输速率为1000 Gbit/s , 有
一 台 巨 型 计铸机 向 一 台个人 电(cid:7143)以1 Gbit/s 的速率传送文件 。 显然 ， 网络本身的带 宽 是 足够
大的， 因而不存在 产 生 拥 塞的问题。 但流量控制却是必需的， 因为 巨 型计算机必须经常停下

来 ， 以便个人 电 (cid:7144) 来 得及接收。

但 如果有另 一个网络 ， 其链路传输速率为 1 Mbit/s , 而有 1000 台 大 型 计算机连接在这
个网络 上 。 假定 其 中的 500 台 计算机分别向其余的 500 台 计算机以100 kbit/s 的速率发送 文

件 。 那么现在的问题 已 不是 接收端的大型计算机是 否 来 得及接收 ， 而是 整个网络的输入负 载

是否超过网 络所 (cid:7132) 承 受的 。

拥 塞 控制和 流 鼠 控制之 所以常常被 弄 混 ， 是 因 为某 些 拥 塞 控制算法是 向发送 端 发送

控 制 报 文 ， 并告 诉发送端 ， 网络 已出现麻烦 ， 必须放慢发送速率 。 这 点 又和流量控制是很相

似的。

流量控制和 拥 塞 控制的区 别 可以用图 5- 22 的简单比喻来说明 。 图中表示 一 水 龙 头 通过
管 道 向 一个水桶 放 水 。 图 5- 22(a)表示 水 桶 太小 ， 来 不 及 接收注入水 桶的水 。 这 时只好请 求
管 水 龙 头的人把水 龙 头 拧 小 些 ， 以减 缓放水的速率 。 这 就相当于流 量 控制。 图 5- 22( b)表示

虽 然 水 桶 足够 大 ， 但管道中有很狭 窄的地方， 使得管道不通畅 ， 水流被堵 塞 。 这种情况被反

馈 到 管 水 龙头的人 ， 请 求把水 龙 头 拧小 些 ， 以减缓放水的速率 ， 为的是 减 缓水管的堵塞状态 。
这 就 相 当 千拥 塞控制。 请 注 意 ， 同样是把水 龙 头 拧 小 些 ， 但目的是很不 一样的 。

输速率调整

＼

传

小 容 量
接收设备

(a) 流量控制

大容量 ＼飞广一
接 收 设 备

一－夕

(b)

拥 塞控制

图 5-22 流量控制 和 拥 塞控制的 比 喻 （本 图取 自 [TANE l 1 ] 图 6-22 , 特此致 谢 ）

进 行 拥 塞 控 制 需要付出代 价 。 这 首 先需要获得网络 内 部流 量分布的信 息 。 在实 施 拥 塞

控制时 ， 还 需 要 在(cid:7188) 点 之间交 换 信 息和各种命令 ， 以便选择 控制的策略和实施控制。 这样就
产 生 了 额外 开 销 。 拥 塞控制有时需要将 一 些 资源（ 如缓存、 带 宽 等） 分配给个别用户 （或 一
些类别的用户 ） 单独使用 ， 这样就使得网络 资 源不(cid:7126)更好地实现共 享 。 十分明显 ， 在设计拥

塞控制策 略时 ， 必须全面 衡 量得 失 。

在图 5- 23中的横 坐 标是 提 供 的 负载( offe re d load ) ， 代表单位时间内 输入给网络的分组数

目 。 因 此 提供的 负 载 也称 为输 入 负 载或 网 络负 载 。 纵 坐 标是 吞 吐量 ( throughput ) ， 代 表单位
时间 内 从网络输出的分组数目 。 具有理想拥 塞控制的网络 ， 在吞 吐量 饱和之前， 网络 吞 吐 量
应等 千 提供的负 载 ， 故 吞 吐 量 曲 线是 45°的斜线 。 但当 提供的负 载超过某一 限度时， 由于网

• 239  •

络 资 源 受 限 ， 吞 吐 量不再增 长而保持为水平线， 即 吞 吐量达到饱和。 这 就表明提供的负 载中
有 一 部 分损 失 掉 了 （ 例如， 输 入 到 网络 的 某 些分组被 某个(cid:7188)点丢弃 了 ）。 虽 然 如此， 在 这种
理 想 的 拥 塞控制作用下， 网络 的 吞 吐 量仍然 维持在其所(cid:7126)达到 的 最 大值。

吞 吐 冕

提 供 的 负 载

图 5-23 拥 塞拧制 所起的作用

但 是 ， 实 际 网 络 的情况就很不相 同 了 。 从图 5-23 可看出， 随 着 提 供 的 负 载 的 增 大， 网
络 吞 吐 量 的 增长速率逐渐减小。 也就是 说， 在网络 吞 吐 量 还 未达到 饱和时， 就 已经有一部分
的输入分 组 被 丢弃 了 。 当网络 的 吞 吐 量明显地小于理想 的 吞 吐 量 时 ， 网络就进入 了 轻度 拥 塞
的 状 态 。 更 值 得 注 意 的 是 ， 当 提供 的 负 载达到某 一数值时， 网 络 的 吞 吐 量 反而随 提供 的 负 载
的 增 大 而 下 降 ， 这 时 网络就进入 了 拥 塞状态。 当 提供 的 负 载 继续增 大到某 一数值时， 网 络 的
吞 吐 量 就下 降 到 零 ， 网络 已无法工作， 这 就是 所 谓 的 死锁(de adlock )。

从 原理上 讲， 寻 找拥 塞 控 制 的 方 案 无非是 寻找使不等 式(5-7)不再成立 的条件。 这 或者
是 增 大 网 络 的 某 些 可用 资 源（ 如业 务 繁 忙 时增 加 一 些链路， 增 大链路的 带 宽 ， 或使额外 的 通
信 量 从 另 外 的 通路分流 ） ， 或 减少一 些 用 户对某 些 资 源 的需求（如拒 绝接 受 新 的 建 立连接 的
请 求 ， 或 要 求用户 减 轻 其负 荷 ， 这 属 于 降 低 服 务 质 量）。 但 正 如上 面 所 讲过 的 ， 在 采用某种

措 施 时 ， 还 必须考虑 到 该措 施 所带 来 的 其他 影 响 。

实 践 证 明 ， 拥 塞 控 制是很难 设 计 的 ， 因为它是 一个动 态 的 （而不 是 静 态 的 ） 问 题。 当
前 网 络 正 朝 着高速化 的 方 向发展 ， 这 很容易出现缓存不够大而导(cid:7176)分组 的 丢 失。 但分组的 丢

失 是 网络发生拥 塞 的 征 兆 而不是 原 因。 在许多情况下， 甚 (cid:7169) 正是 拥 塞 控 制机制 本 身 成为 引 起
网 络性 (cid:7140) 恶化 甚 (cid:7169) 发 生 死锁 的 原 因。 这 点应特别 引 起重视。

由 千 计 算 机 网 络是 一个很 复杂 的系统 ， 因此可以从控 制理论 的 角 度来 看拥 塞 控 制这个
问 题 。 这 样 ， 从大 的 方面看， 可以分为开环控制和闭环控制两种方法。 开 环 控 制就是在设计
网 络 时 事 先将 发 生 拥 塞 的 有 关 因 素考 虑 周 到 ， 力 求 网络 在 工 作时不产 生 拥 塞 。 但 一 旦 整个系
统 运 行 起来， 就不再中途进行改正 了 。

闭 环 控 制是 基于反馈环路的 概 念， 主要有以下 几种措施：

( I ) 监 测 网络系统以便检测 到 拥 塞 在何 时 、 何处发 生 。

( 2 ) 把拥 塞发生 的 信 息传送到可采取行动 的地方。

( 3 ) 调 整 网络系统 的 运行以解决出现 的 问题。
有 很 多 的 方 法可用来 监 测 网 络 的 拥 塞 。 主要 的 一 些 指 标是： 由 千缺少 缓 存 空 间 而被 丢

弃 的 分组 的 百 分数 、 平均队 列长度、 超 时重传的分组数 、 平均分组时延 、 分组时 延 的 标 准 差 ，

等 等 。 上 述 这 些指标 的 上 升 都标 志 着 拥 塞发生 的可(cid:7126)性增 加 。

一 (cid:7186) 在 监 测 到 拥 塞发生 时， 要 将 拥 塞 发 生 的 信 息 传 送到 产 生 分组 的 源 站 。 当然， 通知

拥 寒 发 生 的 分 组 同样 会使网络 更加拥 塞 。

• 240 •

另 一种方法是 在路由器转发的分组 中 保 留 一个比特 或 字 段， 用 该 比 特 或 字 段的值表示
网络没有拥 塞或产 生 了 拥 塞。 也可 以 由一 些 主机或路由器周 期性地发出探测 分组， 以 询问拥
塞是 否 发 生。

此外 ， 过千频 繁 地采 取行动 以 缓和 网 络 的拥 塞 ， 会 使系统 产 生不稳定 的 振 荡 。 但过 于

迟缓地采取行动 又不具有任 何 实用价值。 因此， 要采用某种折 中 的方法， 但 选 择 正 确的时间

常数是相当 困 难的。

下面就来 介 绍更加 具 体的防 止 网络拥 塞的方法。

5 . 8 .2  TCP

的 拥 塞控 制 方法

TCP 进 行 拥 塞 控 制的算 法 有 四 种 ， 即 慢 开 始 (s

( conge s non  avo1dance) 、 快 重传( fas t re trans mIt)和快恢复( fas t recove ry) （见草 裔含善暑

low-s tart) 、 拥 塞 避 免 霍皇

案 标 准 RFC 568 1)。 下 面就介绍这 些算法的原理。 为了集 中 精 力 讨 论拥 塞控

制 ， 我 们 假定：

扫 一 扫

视韧讲解

( 1) 数据是 单 方向传送的， 对方只 传送确 认 报文。
( 2) 接收方总是有足够大的缓存空间， 因 而发送窗 口 的大 小 由网络的拥 塞程度来 决定。

1 . 慢开始和拥 塞避免

下 面 讨 论的拥 塞 控制也叫 作 基 于 窗 口 的拥 塞 控制。 为此， 发送方维 持 一个叫作拥 塞 窗
口 cwnd ( conge s tion  window)的状 态变量。 拥 塞 窗口的大小 取 决千 网络的拥 塞程度， 并且是
动 态变化 着的。 发 送 方 让 (cid:7152) 己 的 发 送 窗 口 等千 拥 塞 窗 口 。 根据假定 ， 对方的接收窗 口 足够大，
发送方在发送数据时， 只 需考虑发送方的拥 塞 窗 口 。

发送方控制拥 塞 窗 口的原 则 是 ： 只 要网络没 有出现拥 塞 ， 拥 塞 窗 口 就可 以 再增大一 些 ，
以便把更多的分组发送出去， 这样就可 以提高网络的利 用率。 但只要 网络出现拥 塞 或有可(cid:7126)
出 现拥 塞， 就必须把拥 塞 窗口减小一些， 以 减少注入到 网络 中 的分组数， 以便缓解网络出现
的拥 塞。

发送方 又 如何 知道 网 络发生 了拥 塞 呢 ？ 我 们 知道， 当网络发生 拥 塞 时， 路由器就要把

来 不及处理而排不上 队的分组丢弃。 因此只 要发送方没有按时收到对方的确认报文， 也就是
说， 只 要出现了超时， 就可 以 估计可(cid:7126)在网络某处出现了拥 塞。 现在通信线路的传输质 量 一
(cid:7182)都很好， 因传输出差 错而丢弃分组的概率是很小的（ 远 小千 l %）。 因此， 发送方在超时
重传计时器启 动 时， 就判 断 网 络 出 现 了 拥 塞。

下 面将 讨 论拥 塞 窗口 cwnd 的大小是 怎样变化 的。 我 们 从 “ 慢开始算法
慢开始算法的思路是 这样的： 当主机在 已 建 立的 TCP 连接上开始 发 送数据时 ， 并不清

讲起。

”

楚 网络当前的负 荷情况 。 如 果立 即 把大量数据字(cid:7188)注入到 网 络， 那么就有可(cid:7126) 引 起网络发生
拥 塞。 经验证明， 较好的方法是 先探测 一下， 即 由 小 到 大逐渐增大注入到 网 络 中 的 数 据字(cid:7195) ，
也就是说， 由 小 到 大 逐渐增大 拥 塞窗 口 数 值。

旧 的规定是这样的： 在 刚 刚 开始发送报文段时， 先把初始拥 塞 窗口 cwnd 设置为1 (cid:7169) 2

个发 送 方 的 最 大报文段 SMSS (Se nde r  Maximum  Se gment  Size )的数值， 但新的 RFC 568 1
（ 草 案标 准） 把初始拥 塞 窗 口 cwnd 设置为不超过 2 (cid:7168)4 个 SMSS 的数值。 具 体的规定如下：

若 SMSS >  2190 字节，

则设置初 始拥 塞 窗 口 cwnd =  2 x  SMSS 字(cid:7188)， 且 不得超过 2个报文 段。

若 ( SMSS > 10 95 字(cid:7188)） 且 C SMSS ::S  21 90 字(cid:7188) ），

•  241

•

则设置初始拥 塞 窗 口 cwnd = 3 x  SMSS 字(cid:7188)， 且不得超过3个报文 段。

若 SMSS � 10 95 字(cid:7188)，

则设置初始拥 塞 窗口 cwnd = 4  x  SMSS 字(cid:7188)， 且不得超过4个报文 段。

可见这个规定 就是 限制初始拥 塞 窗口的字(cid:7188)数。
慢 开始 规 定 ， 在每收到 一个对新 的 报 文 段 的 确 认 后 ， 可 以 把拥 塞 窗 口增加最多一个

SMSS 的数值。 更具体些， 就是

拥 塞 窗口 cwnd 每 次的增加量 ＝ min ( N,  SMSS )

(5-8 )

其中 N 是 原先未 被 确 认的、 但现在被 刚收到 的 确 认 报 文 段 所 确 认的字(cid:7188)数。 不难看 出 ，

当 N < SMSS 时， 拥 塞 窗口每次的增加量要小千 SMSS。

用这样的方法逐步增大发送方 的拥塞窗口 cwnd, 可 以 使分组注入到网络的速率更加合理。

下 面用例子说 明慢 开始 算法的原 理。 请 注 意 ， 虽然 实 际 上 TCP用字(cid:7188)数作为窗 口大小

的单位。 但为叙述方便起见 ， 我们用 报文段 的个数作 为 窗 口 大 小 的 单位， 这样可 以使用较小
的数字来 阐明拥 塞控制的原理。

在一开始发送方先设置 cwnd =  1, 发送第 一个报文段， 接收方 收到后就发送确 认。 慢 开
始 算 法 规定 ， 发送方每收到 一个对新报文 段 的 确 认（对重 传的确 认不算在 内 ）， 就把发送方
的拥 塞 窗口加1 。 因此， 经过一个往返时延 RTT后， 发送方就增 大 拥 塞 窗口， 使 cwnd =  2,
即发送方现在可连续发送两个报 文 段。 接收方收到这 两个报文 段 后 ， 先后发回两个确 认。 现

在 发送方收到 两个确认， 根据慢开始算法， 拥 塞 窗口就应 当加 2, 使拥 塞 窗口从 cwnd =  2增
加到 cwnd = 4, 即可连续发送4 个报文 段。 发送方收到这4 个确 认后， 就可 以把拥 塞 窗 口再

加4, 使 cwnd =  8 （ 如图 5- 24 所示 ）。 显然 ， 发送方并不是要在所有的确 认 都收齐 了 之后才
调 整 其 拥 塞 窗口， 而是收到 一个确 认就调 整 一下拥 塞 窗 口 ， 抓 紧时间发送报 文 段。 但这样的
细 节 不是 我们 现在所要研究 的 ， 我们 想知道的 只 是 拥 塞 窗口的大(cid:7177)增长趋 势 。

发 送 方

桵 收 方

图5-24 发送方每收到 1 个确 认 就把拥 塞 窗 口 加 1

＂

慢

由此可见， 慢开始的

” 并不是指 cwnd 的增长速率慢， 而是指在 TCP 开始发送报
文 段时， 只发送一个报文段， 即设置 cwnd =  1, 目的是 试探一下 网 络的拥 塞情况， 然后视情
况 再逐渐增大 cwnd。 这 当 然 比一开始设置大的 cwnd 值， 一下子把许多报文 段 迅速注入到
网络要

“ 慢 得 多 ”。 这对防 止 出 现网络 拥 塞是 一个非常好的方法。

为了防 止 拥 塞 窗口 cwnd 增 长 过大 引 起网络拥 塞 ， 还 需要设置一个慢开始 门 限 s

s thre s h

状 态 变量（可 以把 门 限 s

s thre s h 的数值设置大些， 例如达到发送窗 口的最大容许值）。 慢 开

•  24 2 •

始门限 s

s thre s h 的用法如下：

当 cwnd < s

s thre s h 时， 使用上述 的慢开始算法。

当 cwnd > s

s thre s h 时， 停 止使用慢开始算法而改用拥 塞避免算法。

s thre s h 时， 既可 使用慢开始算法， 也可 使用拥 塞 避 免 算法。

当 cwnd = s
拥 塞避免算法的目的是 让 拥 塞 窗 口 cwnd 缓慢地增大（具 体算法见[ RFC 568 1 ] ）。 执行算
法后的结果大 约是 这样的： 每经过一个往返时间 RTT, 发送方的拥 塞 窗 口 cwnd 的大小就加
“ AI
1 ' 而 不是 像 慢 开始 阶 段 那样加 倍 增 长 。 因 此在 拥 塞 避 免 阶 段 就 称 为
e) ， 表明在拥 塞 避 免 阶段 拥 塞 窗 口 cwnd 按线性规律缓 慢增 长 ， 比慢开始

(Additive  Incre as

加 法 增 大

“

算法的拥 塞 窗口增长速率缓慢得多。

可 以用 曲 线 来说明 TCP的拥 塞 窗口 cwnd 是 怎样随时间变化 的（如 图 5 -25 所示 ） 。 但这
里 请特 别 注 意 横 坐 标 采 用 的单 位是 往返 时延 RTT。 在实 际的互 (cid:7110) 网中 ， TCP 发送的每一 个
报 文 段的往返时延 RTT 都是 不一样的（不会 像图 5-24 中所画出的那样很理想 的情况 ）。 但
在这里我们是 讲 解拥 塞控制的原理， 因此应当把图中的 RTT 理解为一 个大(cid:7175)的时间， 在这
样的时间之 内 ， 发送方发出了一 批报 文 段 ， 并且 都收到 了 接收方的确 认 。 图 5-25 中的数字
0 (cid:7168) 0 是特 别要注 意的几个 点 。 现假定 TCP的发送窗口 等 千 拥 塞 窗口。

拥 寒 窗 口 cwnd

｀言忙l1『 }::：

8

超 同 （ 网 络 发生拥 悲 ， 执 行 幔 开 始 算 法 ）
＠
第1
人

l

储
/

:�3 -A�:．二央

（二二

e1：

「 - －

－ － - － －尸 了

－ － －

－

－ － －

－ －

－－－－－－－－－－－ 1

『 - － － － － - － － － 7- -：- － － － - － - － -

-

- 1
，
: ;:._

、＼

2 次 调 整 ssthresh

－

－

－

－

－

－

－ －

－

一

＿ ＿ ＿ ＿

0

2

4

6

8

1 0

1 2

1 4

1 6

1 8   20  22  24

往返 时 延 RTT

图 5 -25 TCP 拥 塞 窗 口 cwnd 在 拥 塞控制 时 的 变 化情 况

当 TCP连接 已 建 立后 ， 把拥 塞 窗口 cwnd 置为 1 。 在本 例 中 ， 慢开始门限的初始值设置
为 1 6个报 文 段 ， 即 s sthre s h =  1 6。 在执行 慢开始算法阶段 ， 每经过一个往返时间 RTT, 拥
s thre s h 时 （ 图中的点 0 , 此时
塞 窗口 cwnd 就加倍 。 当拥 塞 窗 口 cwnd 增长到慢开始 门 限 值 s

拥 塞 窗 口 cwnd =  1 6) ， 就 改为执行拥 塞 避 免算法 ， 拥 塞 窗口按线性 规 律 增 长。 但 请 注 意 ，
” 并 非 完 全避 免拥 塞 ， 而是 让 拥 塞 窗口增 长得缓慢 些 ， 使 网 络不容 易 出 现拥 塞 。
“

拥 塞 避 免

当拥 寒 窗 口 cwnd =  24 时， 网络 出 现 了 超时（图中的点＠ ）， 这 就是 网络 发生拥 塞的标志。

千是 调 整门限值 s

s thre s h = cwnd / 2 = 1 2, 同时设置拥 塞窗口 cwnd =  1, 执行慢开始算法。

按 照慢开始算法 ， 发送 方每收到 一个对新报文段的确 认 AC K, 就把拥 塞 窗口 值加 1 。
s thre s h 第1 次调 整后的数值 ） ， 改

s thre s h  =  1 2 时（图中的点＠ ， 这 是 s

当 拥 塞 窗口 cwnd =  s

为执行 拥 塞 避免算法， 拥 塞 窗口按线性规律增大。

当拥 塞 窗口 cwnd =  1 6 时（ 图中的点O ) ， 出现了 －个新 的情况 ， 就是发送方一 连收到3

个对 同 一个报文 段的重复确认（图中记为3-AC K)。 关 于这个问题要解释如下。

有时 ， 个 别 报 文 段会 在 网 络中意外 丢 失 ， 但 实 际 上 网络并未发生 拥 塞 。 如果发送方迟

迟收不到确 认 ， 就会产生超时， 并误认为网络发生 了 拥 塞 。 这 就导 (cid:7175)发送方错 误地启 动 慢 开

始 ， 把拥 塞 窗口 cwnd 又设置为1, 因而不必要地降低了传输效率。

•  243 •

采用快重传算法可 以 让发送方 尽 早 知 道 发 生 了 个 别 报 文 段 的 丢 失 。 快重传算法首先要

求接 收方不要 等 待 (cid:7165) 已发送数据 时 才 进 行 捎 带 确认， 而 是 要 立 即 发 送确 认， 即使收到了失序

的 报文段也要 立即发 出对 已 收 到 的 报 文 段 的 重 复 确 认。 如 图 5-26 所示 ， 接 收方收到了M ] 和

M 2 后 都分别 及时发 出了确认。 现假 定 接 收 方 没有收到 M 3 但却 收到 J M4 。 本 来 接收方可以

什 么 都不做。 但按照快重传 算法， 接 收 方 必须 立 即 发 送 对 M2 的 重复确认， 以便让 发 送方及

早知道接收方没有收到报 文 段 M3。 发送方接 着 发送 M 5 和 M6。 接 收方收到 后 也仍要 再次分

别发出对 M2 的重复 确认。 这样， 发送方 共 收 到了接 收 方的4 个对 M2 的确认， 其中后3个
快重传算法规 定 ， 发送方 只 要 一连收到3 个重复确认 ， 就可知道现在并未出
”)。

都是 重 复确 认
现网络 拥 塞 ， 而只 是 接 收 方 少 收到 一个报 文 段 M 3, 因 而立 即 进行重传 M 3（即

快重传

“

c

使用快重传可 以 使 整个网络的吞吐量 提高约 20 % 。

发达 方

接收方

收 到3 个 连 续 的
对 M2 的 重 复确 认 ，
立 即 快重 传 M 3

确认 M l
确 认 M2

重复确认 M2
正 复 确 认 M2
重复确认 M2

图 5-26 快 重 传 的 示 意 图

因此， 在图 5-25 中 的点 O ， 发送方知 道 现在 只 是丢失了个别的报文段。 千是 不启 动 慢

开始 ， 而是执行快恢复算法。 这 时 ， 发送方第 2次调 整门限值 ， 使 s

s thre s h =  cwnd /  2 =  8 ,

同 时设置拥 塞 窗口 cwnd = s

s thresh = 8 （ 见图 5- 25 中的点 0 ) ， 并开始执行拥 塞 避免算法。

在图 5- 25 中还标注有 “ TCPReno 版本
请 注 意 ， 也有的快 恢 复 实 现 是把快 恢 复开始时的拥 塞 窗口 cwnd 值再增大一 些（ 增大 3
s thre sh + 3 x  M SS 。 这样做的理由是 ： 既然 发送方收到3个

， 表 示 区 别于老的 TCPTahao 版本。

个报文 段的长度 ） ， 即 等于新的 s

”

重 复的确认， 就表明有3个分组 已 经 离开 了 网 络。 这3 个分组不再消 (cid:7106) 网络的资源而是 停 留

在 接 收 方的缓存中 （ 接 收方发送 出 3 个重复的确 认 就 证明 了 这个事 实 ） 。 可见现在网络中并

不是 堆积了分组而是 减少了3个分组。 因此可 以 适 当 把 拥 塞 窗 口 扩大些 。

从 图 5- 25 可 以 看 出 ， 在拥 寒 避 免 阶段， 拥 塞 窗 口 是 按 照线性 规律增大的 ， 这就是前面
提到 过的加 法增大AI 。 而一 旦 出 现超时或3个重 复的确 认 ， 就要 把门限值设置为当前拥 塞
窗 口值的 一 半 ， 并大大减 小拥 塞 窗 口 的 数 值 。 这 常 称 为 ＂ 乘 法 减 小 “ MD ( Multiplicative
De crease )。 二 者 合在一起就是 所 谓 的AIMD 算法。

采用这样的拥 塞 控 制 方法使得 TCP 的性 (cid:7127) 有 明显的改进[STEV94 ] [ RFC 5681 ] 。

根据 以 上所述 ， TC P 的拥 塞控制可 以 归 纳 为 图 5-27的流程图 。 这个流程图就比图 5- 25

所示的特 例要更加全面些 。 例 如 ， 图 5-25 没有说 明 在 慢开始阶 段 如果 出 现 了超时（即 出 现

了网络 拥 塞） 或 出 现 3-AC K, 发 送 方 应 采 取 什 么 措 施 。 但从 图 5-27的流程 图 就可 以很明确

地知道发送方应 采取的措 施 。

•  244  •

ssthresh = cwnd I 2
cwnd =  1

TCP

连接建立

慢开始

cwnd =  1

拥 塞 窗 口
按指 数 规 律 增 大

cwnd �  ssthresh

超 时

拥 塞避免

cwnd

拥 塞 窗 口
按线性规律增 大

3

个 重 复
ACK

的

3

个 重 复
ACK

的

TCP

连接 释放

图5-2 7 TCP 的拥 塞控制的流程 图

在 这 一 节的开始我们 就假定 了 接收 方 总 是有足 够大的缓 存 空 间， 因而发送窗 口的大小

由 网络 的 拥塞 程度来决 定 。 但 实际 上 接收 方的缓存 空间总是有限的。 接收方根据 自 己的接收

能力 设 定 了 接收方窗 口 rwnd , 并 把这个窗 口值写入 TCP首部中的窗 口字段 ， 传送给发送方 。

因此， 接收方 窗 口 又称为通 知 窗 口 ( adve rtis

e d window )。 因此， 从 接收 方 对发送方的流量 控

制的角 度考虑， 发送方的发送 窗 口 一定不能超过对方给出 的接收方窗 口 值 rwnd。

如果把本节所讨论的 拥塞 控制和 接收 方 对发送方的流 瞿 控制一 起 考 虑 ， 那么 很 显 然 ，

发送方的窗 口的 上 限 值应当取为接收 方 窗 口 rwnd 和 拥塞 窗 口 cwnd 这 两 个变量中较小的一

个， 也就是说：

发送方 窗 口的上限值 ＝ Min (rwnd,  cwnd]

( 5-9 )

式( 5-9 )指出：
当rwnd < cwnd 时， 是接收方的接收 能力 限制发送方 窗 口的最大值 。
反之 ， 当 cwnd < rwnd 时， 则是网络的 拥塞 程度 限制发送方窗 口 的最大值 。
也就是说 ， rwnd 和 cwnd 中 数值较小的一个，

控制了发送方发送 数据 的速率 。

5.8.3  主 动 队 列 管 理 AQM

上一节讨论的 TCP 拥塞 控制 并 没有和网络 层采取的策 略 联 系 起来。 其实 ， 它 们 之间有

着 密 切的关系 。

例 如 ， 假定 一个 路由器对 某 些分组的 处理时间特别长 ， 那 么 这 就可能使 这 些分 组中的

数据 部分 （即 TCP 报 文 段） 经过很长时间才能到达终点 ， 结果 引 起发送方对这 些报 文 段的

重传 。 根据 前 面所讲的， 重传 会 使 TCP 连接的发送端认为在网络中发 生 了 拥塞 。 于是在

TCP的发送端 就采取 了 拥塞 控制措施 ， 但实际 上网络 并 没有发 生 拥塞 。

网络 层的策 略 对 TCP 拥塞 控制影 响最大的就是路由器的分组丢 弃 策 略 。 在最简 单 的情
况下 ， 路由器的队列通常都按照 “ 先进先 出 “ FI FO ( Firs t I n  Firs t  Out) 的 规 则 处理到来的分
组 。 山 千 队列长度 总 是有限的， 因此当队列已满时， 以后再到达的所有分组 （ 如果能够继

•  245 •

续 排 队 ， 这 些 分组都将 排 在 队 列 的 尾部） 将 都 被 丢弃。 这 就叫作 尾 部 丢 弃 策 略 ( tail-drop

policy )。

路 由 器的尾部丢弃往往会 导 (cid:7175) 一 连 串 分组的丢 失 ， 这 就使发送方 出 现超 时重传， 使

TCP进入拥塞 控 制 的慢 开始状态， 结果使 TCP连接的发送方突 然 把数据的发送速率降低到

很小的数值 。 更为严重的是， 在网络 中 通常有很多的 TCP 连接（它们有不 同的源 点和终点 ），

这 些连接中的报文 段通常是复用在 网 络 层的 IP 数据报中传 送的。 在这种情况下， 若发生 了

路由器中的尾部丢弃， 就可(cid:7126) 会 同时影 响 到很多条 TCP连接， 结果使这 许多 TCP连接在 同

一 时 间 突 然 都进入到慢 开始状态 。 这 在 TCP 的术 语中称 为全 局 同 步( global

s ynchronization )。

全局 同 步使得全网的通信 量 突 然 下 降 了很多， 而在网络恢 复 正常后， 其通信 量 又 突 然 增大很

多。

为了避 免发生 网络中的全 局 同 步 现象， 在1 998 年 提 出了主动 队 列 管理 AQM (Active

Que ue  Manage me nt )。 所 谓 “ 主动

”

就是 不要等到 路 由 器的 队 列 长度 已经达到 最大值时才不

得不丢弃后面到达的分组。 这样就 太 被 动了。 应当在 队 列 长 度达到 某个值得警惕 的数值时

（即当网络拥 塞有了某 些拥 塞 征 兆 时 ）， 就主动丢弃 到达 的 分组。 这样就 提醒 了发送方放慢

发送的速率， 因而有可(cid:7126)使网络 拥 塞的程度减轻， 甚 (cid:7169) 不 出 现网络 拥 塞 。 AQM 可以有不 同

实现方法， 其中 曾 流行多年的就是 随机早期检测 RED ( Random  Early De te ction) o  RED还有

几个不 同的名 称， 如 Random Early Drop 或 Random Early Dis card（随机早 期丢弃 ）。

实现 RED 时需要使路由器维持两个参数， 即 队 列 长度 最小门限和最大门限 。 当每一个

分组到达时，

RED就按照规 定的算法先计算当前的平均队 列 长度。

(1 ) 若 平均 队 列 长度小于最小门限， 则 把新到达的分组放入队 列 进行排 队 。

( 2)若平均队列 长度超过最大门 限， 则 把新到达的分组丢弃。
(3 ) 若平均队 列 长度在最小门 限 和 最大门限之间， 则 按照某一 丢弃概率 p 把新到达的分

组丢弃 （ 这 就体现了丢弃分组的随机性 ）。

由此可见，

RED 不是 等 到 已经发生 网络拥 塞后才把所有在 队 列 尾部的分组全部丢弃，

而是 在检测 到 网络 拥 塞的早期征兆时（即 路由器的平均队 列 长度达到 一定数值时）， 就以概

率 p 丢弃个别 的分组， 让 拥 塞 控 制 只 在个别的 TCP连接 上进行， 因而避 免发生全 局 性的拥

塞 控制。

在 RED 的操作 中 ， 最难处理的就是丢弃概率 p 的选择， 因 为 p 并不是个常数。 对每一

个到达的分组， 都必须计算丢 弃 概率 p 的数值。 I ETF 曾 经推荐 在 互 (cid:7110) 网中的路 由 器使用

RED机制[ RFC 230 9]， 但多年的实 践证明，
公布的 RFC 756 7 已经把过去的 RFC 230 9 列 为 “ 陈 旧 的

RED的使用效果并不 太 理 想 。 因此， 在 201 5 年
＂， 并且不 再推荐使用 RED。 对路

由器进行主动 队 列 管理 AQM 仍是必要的。 AQM 实 际 上就是对路 由器中的分组排 队进行智

(cid:7126)管理， 而不是简单地把 队 列的尾部丢弃。 现在 已经有几种不 同的算法来 代 替 旧 的 RED, 但
都还在实验 阶段。 目前还没有一种算法(cid:7126)够成为I ETF 的标准， 读者 可注 意这 方面的进展。

5 . 9   TC P 的 运输连接管理

TCP是 面向连接的协 议 。 运输连接是 用来 传送 TCP报文的。 TCP运输连接的建立和释

•  246  •

