### 关键词提取 - 分块 1
收方就发出确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报
文段，而是把数据积累成足够大的报文段，或达到接收方缓存的空间的一半大小。
上述两种方法可配合使用。使得在发送方不发送很小的报文段的同时，接收方也不要在缓存刚刚有了一点小的空间就急忙把这个很小的窗口大小信息通知给发送方。
5.8TCP的拥塞控制一5.8.1拥塞控制的般原理在计算机网络中的链路容量（即带宽）、交换(cid:7188)点中的缓存和处理机等，扫一扫寄恩畸启视频讲解都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所(cid:7126)
提供的可用部分，网络的性(cid:7126)就要变坏。这种情况就叫作拥塞(congestion)。可以把出现网络拥
塞的条件写成如下的关系式：区对负源的需求＞可用资掠(5-7)若网络中有许多资源同时呈现供应不足，网络的性(cid:7126)就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。

**关键词**: 计算机网络 窗口大小 拥塞控制 链路容量 交换点 缓存 处理机 资源 需求 可用部分 网络性能 拥塞 输入负荷 吞吐量


### 关键词提取 - 分块 2
有人可(cid:7126)会说：“只要任意增加一些资源，例如，把(cid:7188)点缓存的存储空间扩大，或把链路更换为更高速率的链路，或把(cid:7188)点处理机的运算速度提高，就可以解决网络拥塞的问题。”
其实不然。这是因为网络拥塞是一个非常复杂的问题。简单地采用上述做法，在许多情况下，
不但不(cid:7126)解决拥塞问题，而且还可(cid:7126)使网络的性(cid:7126)更坏。
网络拥塞往往是由很多因素引起的。例如，当某个(cid:7188)点缓存的容量太小时，到达该(cid:7192)点的分组因无存储空间暂存而不得不被丢弃。现在设想将该(cid:7188)点缓存的容量扩展到非常大，千是凡到达该节点的分组均可在(cid:7188)点的缓存队列中排队，不受任何限制。由千输出链路的容量和处理机的处理速度并未提高，因此在这队列中的绝大多数分组的排队等待时间将会大大增加，结果上层软件只好把它们进行重传（因为早就超时了）。由此可见，简单地扩大缓存的存储空间同样会造成网络资源的严重浪费，因而解决不了网络拥塞的问题。

**关键词**: 计算机网络 链路 缓存 存储空间 处理机 运算速度 网络拥塞 分组 排队等待时间 重传


### 关键词提取 - 分块 3
又如，处理机处理的速率太低可(cid:7126)引起网络的拥塞。简单地将处理机的速率提高，可
(cid:7126)会使上述情况缓解一些，但往往又会将瓶颈转移到其他地方。问题的实质往往是整个系统
的各个部分不匹配。只有所有的部分都平衡了，问题才会得到解决。
拥塞常常趋千恶化。如果一个路由器没有足够的缓存空间，它就会丢弃一些新到的分
组。但当分组被丢弃时，发送这一分组的源点就会重传这一分组，甚(cid:7169)可(cid:7126)还要重传多次。
这样会引起更多的分组流入网络和被网络中的路由器丢弃。可见拥塞引起的重传并不会缓解
网络的拥塞，反而会加剧网络的拥塞。
拥塞控制与流量控制的关系密切，它们之间也存在着一些差别。所谓拥塞控制就是防
止过多的数据注入到网络中，这样可以使网络中的路由器或链路不(cid:7173)千过载。拥塞控制所要
做的都有一个前提，就是网络(cid:7129)够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉

**关键词**: 计算机网络 网络拥塞 路由器 分组 流量控制 拥塞控制


### 关键词提取 - 分块 4
做的都有一个前提，就是网络(cid:7129)够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉
及所有的主机、所有的路由器，以及与降低网络传输性(cid:7126)有关的所有因素。但TCP连接的端点只要迟迟不(cid:7126)收到对方的确认信息，就猜想在当前网络中的某处很可(cid:7126)发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因。（是访问某个服务器的通信量过大？还是在某个地区出现(cid:7160)然灾害？）相反，流量控制往往是指点对点通信量的控制，是个端到端的问题（接收端控制发送•238•端）。流量控制所要做的就是抑制发送端发送数据的速率，以便接收端来得及接收。
可以用一个简单例子说明这种区别。设某个光纤网络的链路传输速率为1000Gbit/s,有
一台巨型计铸机向一台个人电(cid:7143)以1Gbit/s的速率传送文件。显然，网络本身的带宽是足够
大的，因而不存在产生拥塞的问题。但流量控制却是必需的，因为巨型计算机必须经常停下来，以便个人电(cid:7144)来得及接收。

**关键词**: 网络负荷 拥塞控制 路由器 传输性 TCP连接 确认信息 网络中的某处 发生拥塞 具体原因 流量控制 点对点通信量 端到端的问题 接收端 发送端 数据的速率 光纤网络 链路传输速率 巨型计算机 个人电脑


### 关键词提取 - 分块 5
但如果有另一个网络，其链路传输速率为1Mbit/s,而有1000台大型计算机连接在这
个网络上。假定其中的500台计算机分别向其余的500台计算机以100kbit/s的速率发送文件。那么现在的问题已不是接收端的大型计算机是否来得及接收，而是整个网络的输入负载是否超过网络所(cid:7132)承受的。
拥塞控制和流鼠控制之所以常常被弄混，是因为某些拥塞控制算法是向发送端发送控制报文，并告诉发送端，网络已出现麻烦，必须放慢发送速率。这点又和流量控制是很相似的。
流量控制和拥塞控制的区别可以用图5-22的简单比喻来说明。图中表示一水龙头通过
管道向一个水桶放水。图5-22(a)表示水桶太小，来不及接收注入水桶的水。这时只好请求
管水龙头的人把水龙头拧小些，以减缓放水的速率。这就相当于流量控制。图5-22(b)表示虽然水桶足够大，但管道中有很狭窄的地方，使得管道不通畅，水流被堵塞。这种情况被反馈到管水龙头的人，请求把水龙头拧小些，以减缓放水的速率，为的是减缓水管的堵塞状态。
这就相当千拥塞控制。请注意，同样是把水龙头拧小些，但目的是很不一样的。
输速率调整＼传小容量

**关键词**: 计算机网络 链路传输速率 大型计算机 拥塞控制 流控 流量控制 水桶模型 管道堵塞 输速率调整


### 关键词提取 - 分块 6
这就相当千拥塞控制。请注意，同样是把水龙头拧小些，但目的是很不一样的。
输速率调整＼传小容量
接收设备(a)流量控制大容量＼飞广一
接收设备一－夕(b)拥塞控制图5-22流量控制和拥塞控制的比喻（本图取自[TANEl1]图6-22,特此致谢）进行拥塞控制需要付出代价。这首先需要获得网络内部流量分布的信息。在实施拥塞控制时，还需要在(cid:7188)点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就
产生了额外开销。拥塞控制有时需要将一些资源（如缓存、带宽等）分配给个别用户（或一
些类别的用户）单独使用，这样就使得网络资源不(cid:7126)更好地实现共享。十分明显，在设计拥塞控制策略时，必须全面衡量得失。
在图5-23中的横坐标是提供的负载(offeredload)，代表单位时间内输入给网络的分组数目。因此提供的负载也称为输入负载或网络负载。纵坐标是吞吐量(throughput)，代表单位
时间内从网络输出的分组数目。具有理想拥塞控制的网络，在吞吐量饱和之前，网络吞吐量

**关键词**: 计算机网络 流量控制 拥塞控制 缓存 带宽 用户 负载 吞吐量


### 关键词提取 - 分块 7
时间内从网络输出的分组数目。具有理想拥塞控制的网络，在吞吐量饱和之前，网络吞吐量
应等千提供的负载，故吞吐量曲线是45°的斜线。但当提供的负载超过某一限度时，由于网•239•络资源受限，吞吐量不再增长而保持为水平线，即吞吐量达到饱和。这就表明提供的负载中
有一部分损失掉了（例如，输入到网络的某些分组被某个(cid:7188)点丢弃了）。虽然如此，在这种
理想的拥塞控制作用下，网络的吞吐量仍然维持在其所(cid:7126)达到的最大值。
吞吐冕提供的负载图5-23拥塞拧制所起的作用但是，实际网络的情况就很不相同了。从图5-23可看出，随着提供的负载的增大，网
络吞吐量的增长速率逐渐减小。也就是说，在网络吞吐量还未达到饱和时，就已经有一部分
的输入分组被丢弃了。当网络的吞吐量明显地小于理想的吞吐量时，网络就进入了轻度拥塞
的状态。更值得注意的是，当提供的负载达到某一数值时，网络的吞吐量反而随提供的负载
的增大而下降，这时网络就进入了拥塞状态。当提供的负载继续增大到某一数值时，网络的
吞吐量就下降到零，网络已无法工作，这就是所谓的死锁(deadlock)。

**关键词**: 计算机网络 网络资源受限 理想拥塞控制 吞吐量 负载 分组 点丢弃 轻度拥塞 死锁


### 关键词提取 - 分块 8
吞吐量就下降到零，网络已无法工作，这就是所谓的死锁(deadlock)。
从原理上讲，寻找拥塞控制的方案无非是寻找使不等式(5-7)不再成立的条件。这或者
是增大网络的某些可用资源（如业务繁忙时增加一些链路，增大链路的带宽，或使额外的通
信量从另外的通路分流），或减少一些用户对某些资源的需求（如拒绝接受新的建立连接的
请求，或要求用户减轻其负荷，这属于降低服务质量）。但正如上面所讲过的，在采用某种措施时，还必须考虑到该措施所带来的其他影响。
实践证明，拥塞控制是很难设计的，因为它是一个动态的（而不是静态的）问题。当
前网络正朝着高速化的方向发展，这很容易出现缓存不够大而导(cid:7176)分组的丢失。但分组的丢失是网络发生拥塞的征兆而不是原因。在许多情况下，甚(cid:7169)正是拥塞控制机制本身成为引起
网络性(cid:7140)恶化甚(cid:7169)发生死锁的原因。这点应特别引起重视。
由千计算机网络是一个很复杂的系统，因此可以从控制理论的角度来看拥塞控制这个
问题。这样，从大的方面看，可以分为开环控制和闭环控制两种方法。开环控制就是在设计

**关键词**: 死锁 拥塞控制 链路 带宽 服务质量 动态 高速化 缓存 分组丢失 闭环控制 开环控制


### 关键词提取 - 分块 9
问题。这样，从大的方面看，可以分为开环控制和闭环控制两种方法。开环控制就是在设计
网络时事先将发生拥塞的有关因素考虑周到，力求网络在工作时不产生拥塞。但一旦整个系
统运行起来，就不再中途进行改正了。
闭环控制是基于反馈环路的概念，主要有以下几种措施：(I)监测网络系统以便检测到拥塞在何时、何处发生。
(2)把拥塞发生的信息传送到可采取行动的地方。
(3)调整网络系统的运行以解决出现的问题。
有很多的方法可用来监测网络的拥塞。主要的一些指标是：由千缺少缓存空间而被丢弃的分组的百分数、平均队列长度、超时重传的分组数、平均分组时延、分组时延的标准差，等等。上述这些指标的上升都标志着拥塞发生的可(cid:7126)性增加。
一(cid:7186)在监测到拥塞发生时，要将拥塞发生的信息传送到产生分组的源站。当然，通知拥寒发生的分组同样会使网络更加拥塞。
•240•另一种方法是在路由器转发的分组中保留一个比特或字段，用该比特或字段的值表示
网络没有拥塞或产生了拥塞。也可以由一些主机或路由器周期性地发出探测分组，以询问拥
塞是否发生。

**关键词**: 开环控制 闭环控制 反馈环路 监测网络系统 拥塞发生的信息 调整网络系统的运行 缺少缓存空间而被丢弃的分组的百分数 平均队列长度 超时重传的分组数 平均分组时延 分组时延的标准差 通知拥寒发生的分组 路由器转发的分组 比特或字段 探测分组


### 关键词提取 - 分块 10
网络没有拥塞或产生了拥塞。也可以由一些主机或路由器周期性地发出探测分组，以询问拥
塞是否发生。
此外，过千频繁地采取行动以缓和网络的拥塞，会使系统产生不稳定的振荡。但过于迟缓地采取行动又不具有任何实用价值。因此，要采用某种折中的方法，但选择正确的时间常数是相当困难的。
下面就来介绍更加具体的防止网络拥塞的方法。
5.8.2TCP的拥塞控制方法TCP进行拥塞控制的算法有四种，即慢开始(s(congesnonavo1dance)、快重传(fastretransmIt)和快恢复(fastrecovery)（见草裔含善暑low-start)、拥塞避免霍皇案标准RFC5681)。下面就介绍这些算法的原理。为了集中精力讨论拥塞控制，我们假定：扫一扫视韧讲解(1)数据是单方向传送的，对方只传送确认报文。
(2)接收方总是有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度来决定。
1.慢开始和拥塞避免下面讨论的拥塞控制也叫作基于窗口的拥塞控制。为此，发送方维持一个叫作拥塞窗
口cwnd(congestionwindow)的状态变量。拥塞窗口的大小取决千网络的拥塞程度，并且是

**关键词**: 网络拥塞 拥塞控制 慢开始 快重传 快恢复 拥塞避免


### 关键词提取 - 分块 11
动态变化着的。发送方让(cid:7152)己的发送窗口等千拥塞窗口。根据假定，对方的接收窗口足够大，
发送方在发送数据时，只需考虑发送方的拥塞窗口。
发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就可以再增大一些，
以便把更多的分组发送出去，这样就可以提高网络的利用率。但只要网络出现拥塞或有可(cid:7126)
出现拥塞，就必须把拥塞窗口减小一些，以减少注入到网络中的分组数，以便缓解网络出现
的拥塞。
发送方又如何知道网络发生了拥塞呢？我们知道，当网络发生拥塞时，路由器就要把来不及处理而排不上队的分组丢弃。因此只要发送方没有按时收到对方的确认报文，也就是
说，只要出现了超时，就可以估计可(cid:7126)在网络某处出现了拥塞。现在通信线路的传输质量一
(cid:7182)都很好，因传输出差错而丢弃分组的概率是很小的（远小千l%）。因此，发送方在超时
重传计时器启动时，就判断网络出现了拥塞。
下面将讨论拥塞窗口cwnd的大小是怎样变化的。我们从“慢开始算法
慢开始算法的思路是这样的：当主机在已建立的TCP连接上开始发送数据时，并不清讲起。

**关键词**: 动态变化 拥塞窗口 发送窗口 接收窗口 拥塞 超时 慢开始算法


### 关键词提取 - 分块 12
慢开始算法的思路是这样的：当主机在已建立的TCP连接上开始发送数据时，并不清讲起。
”楚网络当前的负荷情况。如果立即把大量数据字(cid:7188)注入到网络，那么就有可(cid:7126)引起网络发生
拥塞。经验证明，较好的方法是先探测一下，即由小到大逐渐增大注入到网络中的数据字(cid:7195)，
也就是说，由小到大逐渐增大拥塞窗口数值。
旧的规定是这样的：在刚刚开始发送报文段时，先把初始拥塞窗口cwnd设置为1(cid:7169)2个发送方的最大报文段SMSS(SenderMaximumSegmentSize)的数值，但新的RFC5681
（草案标准）把初始拥塞窗口cwnd设置为不超过2(cid:7168)4个SMSS的数值。具体的规定如下：若SMSS>2190字节，则设置初始拥塞窗口cwnd=2xSMSS字(cid:7188)，且不得超过2个报文段。
若(SMSS>1095字(cid:7188)）且CSMSS::S2190字(cid:7188)），•241•则设置初始拥塞窗口cwnd=3xSMSS字(cid:7188)，且不得超过3个报文段。

**关键词**: 慢开始算法 初始拥塞窗口cwnd SMSS 网络拥塞 发送方最大报文段


### 关键词提取 - 分块 13
若SMSS�1095字(cid:7188)，则设置初始拥塞窗口cwnd=4xSMSS字(cid:7188)，且不得超过4个报文段。
可见这个规定就是限制初始拥塞窗口的字(cid:7188)数。
慢开始规定，在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个SMSS的数值。更具体些，就是拥塞窗口cwnd每次的增加量＝min(N,SMSS)(5-8)其中N是原先未被确认的、但现在被刚收到的确认报文段所确认的字(cid:7188)数。不难看出，当N<SMSS时，拥塞窗口每次的增加量要小千SMSS。
用这样的方法逐步增大发送方的拥塞窗口cwnd,可以使分组注入到网络的速率更加合理。
下面用例子说明慢开始算法的原理。请注意，虽然实际上TCP用字(cid:7188)数作为窗口大小的单位。但为叙述方便起见，我们用报文段的个数作为窗口大小的单位，这样可以使用较小
的数字来阐明拥塞控制的原理。
在一开始发送方先设置cwnd=1,发送第一个报文段，接收方收到后就发送确认。慢开
始算法规定，发送方每收到一个对新报文段的确认（对重传的确认不算在内），就把发送方

**关键词**: 计算机网络 拥塞窗口 cwnd SMSS 报文段 慢开始算法


### 关键词提取 - 分块 14
始算法规定，发送方每收到一个对新报文段的确认（对重传的确认不算在内），就把发送方
的拥塞窗口加1。因此，经过一个往返时延RTT后，发送方就增大拥塞窗口，使cwnd=2,
即发送方现在可连续发送两个报文段。接收方收到这两个报文段后，先后发回两个确认。现在发送方收到两个确认，根据慢开始算法，拥塞窗口就应当加2,使拥塞窗口从cwnd=2增
加到cwnd=4,即可连续发送4个报文段。发送方收到这4个确认后，就可以把拥塞窗口再加4,使cwnd=8（如图5-24所示）。显然，发送方并不是要在所有的确认都收齐了之后才
调整其拥塞窗口，而是收到一个确认就调整一下拥塞窗口，抓紧时间发送报文段。但这样的
细节不是我们现在所要研究的，我们想知道的只是拥塞窗口的大(cid:7177)增长趋势。
发送方桵收方图5-24发送方每收到1个确认就把拥塞窗口加1＂慢由此可见，慢开始的”并不是指cwnd的增长速率慢，而是指在TCP开始发送报
文段时，只发送一个报文段，即设置cwnd=1,目的是试探一下网络的拥塞情况，然后视情
况再逐渐增大cwnd。这当然比一开始设置大的cwnd值，一下子把许多报文段迅速注入到

**关键词**: 计算机网络 拥塞窗口 往返时延RTT 慢开始算法 确认 报文段


### 关键词提取 - 分块 15
况再逐渐增大cwnd。这当然比一开始设置大的cwnd值，一下子把许多报文段迅速注入到
网络要“慢得多”。这对防止出现网络拥塞是一个非常好的方法。
为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量（可以把门限ssthresh的数值设置大些，例如达到发送窗口的最大容许值）。慢开•242•始门限ssthresh的用法如下：当cwnd<ssthresh时，使用上述的慢开始算法。
当cwnd>ssthresh时，停止使用慢开始算法而改用拥塞避免算法。
sthresh时，既可使用慢开始算法，也可使用拥塞避免算法。
当cwnd=s
拥塞避免算法的目的是让拥塞窗口cwnd缓慢地增大（具体算法见[RFC5681]）。执行算
法后的结果大约是这样的：每经过一个往返时间RTT,发送方的拥塞窗口cwnd的大小就加
“AI
1'而不是像慢开始阶段那样加倍增长。因此在拥塞避免阶段就称为
e)，表明在拥塞避免阶段拥塞窗口cwnd按线性规律缓慢增长，比慢开始(AdditiveIncreas加法增大“算法的拥塞窗口增长速率缓慢得多。

**关键词**: 计算机网络 拥塞窗口cwnd 慢开始算法 慢开始门限ssthresh 拥塞避免算法 往返时间RTT Additive Increase加法增大


### 关键词提取 - 分块 16
可以用曲线来说明TCP的拥塞窗口cwnd是怎样随时间变化的（如图5-25所示）。但这
里请特别注意横坐标采用的单位是往返时延RTT。在实际的互(cid:7110)网中，TCP发送的每一个
报文段的往返时延RTT都是不一样的（不会像图5-24中所画出的那样很理想的情况）。但
在这里我们是讲解拥塞控制的原理，因此应当把图中的RTT理解为一个大(cid:7175)的时间，在这
样的时间之内，发送方发出了一批报文段，并且都收到了接收方的确认。图5-25中的数字
0(cid:7168)0是特别要注意的几个点。现假定TCP的发送窗口等千拥塞窗口。
拥寒窗口cwnd｀言忙l1『}::：8超同（网络发生拥悲，执行幔开始算法）
＠
第1
人l储
/:�3-A�:．二央（二二e1：「-－－－-－－尸了－－－－－－－－－－－－－－－－－－－－1『-－－－－-－－－7--：-－－－-－-－---1
，

**关键词**: 计算机网络 往返时延RTT 拥塞控制 拥塞窗口cwnd


### 关键词提取 - 分块 17
，
:;:._、＼2次调整ssthresh－－－－－－－－－一＿＿＿＿024681012141618202224往返时延RTT图5-25TCP拥塞窗口cwnd在拥塞控制时的变化情况当TCP连接已建立后，把拥塞窗口cwnd置为1。在本例中，慢开始门限的初始值设置
为16个报文段，即ssthresh=16。在执行慢开始算法阶段，每经过一个往返时间RTT,拥
sthresh时（图中的点0,此时
塞窗口cwnd就加倍。当拥塞窗口cwnd增长到慢开始门限值s拥塞窗口cwnd=16)，就改为执行拥塞避免算法，拥塞窗口按线性规律增长。但请注意，
”并非完全避免拥塞，而是让拥塞窗口增长得缓慢些，使网络不容易出现拥塞。
“拥塞避免当拥寒窗口cwnd=24时，网络出现了超时（图中的点＠），这就是网络发生拥塞的标志。
千是调整门限值ssthresh=cwnd/2=12,同时设置拥塞窗口cwnd=1,执行慢开始算法。
按照慢开始算法，发送方每收到一个对新报文段的确认ACK,就把拥塞窗口值加1。

**关键词**: 拥塞控制 往返时延RTT 拥塞窗口cwnd 慢开始门限ssthresh 慢开始算法 拥塞避免算法


### 关键词提取 - 分块 18
按照慢开始算法，发送方每收到一个对新报文段的确认ACK,就把拥塞窗口值加1。
sthresh第1次调整后的数值），改sthresh=12时（图中的点＠，这是s当拥塞窗口cwnd=s为执行拥塞避免算法，拥塞窗口按线性规律增大。
当拥塞窗口cwnd=16时（图中的点O)，出现了－个新的情况，就是发送方一连收到3个对同一个报文段的重复确认（图中记为3-ACK)。关于这个问题要解释如下。
有时，个别报文段会在网络中意外丢失，但实际上网络并未发生拥塞。如果发送方迟迟收不到确认，就会产生超时，并误认为网络发生了拥塞。这就导(cid:7175)发送方错误地启动慢开始，把拥塞窗口cwnd又设置为1,因而不必要地降低了传输效率。

**关键词**: 慢开始算法 拥塞窗口值 sthresh 拥塞避免算法 重复确认(3-ACK)


### 关键词提取 - 分块 19
•243•采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。快重传算法首先要求接收方不要等待(cid:7165)已发送数据时才进行捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认。如图5-26所示，接收方收到了M]和M2后都分别及时发出了确认。现假定接收方没有收到M3但却收到JM4。本来接收方可以什么都不做。但按照快重传算法，接收方必须立即发送对M2的重复确认，以便让发送方及早知道接收方没有收到报文段M3。发送方接着发送M5和M6。接收方收到后也仍要再次分别发出对M2的重复确认。这样，发送方共收到了接收方的4个对M2的确认，其中后3个
快重传算法规定，发送方只要一连收到3个重复确认，就可知道现在并未出
”)。
都是重复确认
现网络拥塞，而只是接收方少收到一个报文段M3,因而立即进行重传M3（即快重传“c使用快重传可以使整个网络的吞吐量提高约20%。
发达方接收方收到3个连续的
对M2的重复确认，
立即快重传M3确认Ml
确认M2重复确认M2
正复确认M2

**关键词**: 快重传算法 捎带确认 报文段 接收方 发送方 拥塞 重复确认 重传


### 关键词提取 - 分块 20
对M2的重复确认，
立即快重传M3确认Ml
确认M2重复确认M2
正复确认M2
重复确认M2图5-26快重传的示意图因此，在图5-25中的点O，发送方知道现在只是丢失了个别的报文段。千是不启动慢开始，而是执行快恢复算法。这时，发送方第2次调整门限值，使ssthresh=cwnd/2=8,同时设置拥塞窗口cwnd=ssthresh=8（见图5-25中的点0)，并开始执行拥塞避免算法。
在图5-25中还标注有“TCPReno版本
请注意，也有的快恢复实现是把快恢复开始时的拥塞窗口cwnd值再增大一些（增大3
sthresh+3xMSS。这样做的理由是：既然发送方收到3个，表示区别于老的TCPTahao版本。
个报文段的长度），即等于新的s”重复的确认，就表明有3个分组已经离开了网络。这3个分组不再消(cid:7106)网络的资源而是停留在接收方的缓存中（接收方发送出3个重复的确认就证明了这个事实）。可见现在网络中并不是堆积了分组而是减少了3个分组。因此可以适当把拥塞窗口扩大些。
从图5-25可以看出，在拥寒避免阶段，拥塞窗口是按照线性规律增大的，这就是前面

**关键词**: 快重传 快恢复 拥塞窗口 ssthresh cwnd 慢开始 TCPReno版本


### 关键词提取 - 分块 21
从图5-25可以看出，在拥寒避免阶段，拥塞窗口是按照线性规律增大的，这就是前面
提到过的加法增大AI。而一旦出现超时或3个重复的确认，就要把门限值设置为当前拥塞
窗口值的一半，并大大减小拥塞窗口的数值。这常称为＂乘法减小“MD(Multiplicative
Decrease)。二者合在一起就是所谓的AIMD算法。
采用这样的拥塞控制方法使得TCP的性(cid:7127)有明显的改进[STEV94][RFC5681]。
根据以上所述，TCP的拥塞控制可以归纳为图5-27的流程图。这个流程图就比图5-25所示的特例要更加全面些。例如，图5-25没有说明在慢开始阶段如果出现了超时（即出现了网络拥塞）或出现3-ACK,发送方应采取什么措施。但从图5-27的流程图就可以很明确地知道发送方应采取的措施。
•244•ssthresh=cwndI2
cwnd=1TCP连接建立慢开始cwnd=1拥塞窗口
按指数规律增大cwnd�ssthresh超时拥塞避免cwnd拥塞窗口
按线性规律增大3个重复
ACK的3个重复

**关键词**: 拥寒避免 乘法减小 AIMD算法 慢开始 网络拥塞 TCP连接建立 指数规律增大 3个重复ACK


### 关键词提取 - 分块 22
按线性规律增大3个重复
ACK的3个重复
ACK的TCP连接释放图5-27TCP的拥塞控制的流程图在这一节的开始我们就假定了接收方总是有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度来决定。但实际上接收方的缓存空间总是有限的。接收方根据自己的接收能力设定了接收方窗口rwnd,并把这个窗口值写入TCP首部中的窗口字段，传送给发送方。
因此，接收方窗口又称为通知窗口(advertisedwindow)。因此，从接收方对发送方的流量控制的角度考虑，发送方的发送窗口一定不能超过对方给出的接收方窗口值rwnd。
如果把本节所讨论的拥塞控制和接收方对发送方的流瞿控制一起考虑，那么很显然，发送方的窗口的上限值应当取为接收方窗口rwnd和拥塞窗口cwnd这两个变量中较小的一个，也就是说：发送方窗口的上限值＝Min(rwnd,cwnd](5-9)式(5-9)指出：
当rwnd<cwnd时，是接收方的接收能力限制发送方窗口的最大值。
反之，当cwnd<rwnd时，则是网络的拥塞程度限制发送方窗口的最大值。
也就是说，rwnd和cwnd中数值较小的一个，控制了发送方发送数据的速率。

**关键词**: 计算机网络 ACK TCP连接释放 拥塞控制 流程图 接收窗口 通知窗口 流量控制 发送窗口 接收方窗口 拥塞窗口 rwnd cwnd


### 关键词提取 - 分块 23
也就是说，rwnd和cwnd中数值较小的一个，控制了发送方发送数据的速率。
5.8.3主动队列管理AQM上一节讨论的TCP拥塞控制并没有和网络层采取的策略联系起来。其实，它们之间有着密切的关系。
例如，假定一个路由器对某些分组的处理时间特别长，那么这就可能使这些分组中的数据部分（即TCP报文段）经过很长时间才能到达终点，结果引起发送方对这些报文段的重传。根据前面所讲的，重传会使TCP连接的发送端认为在网络中发生了拥塞。于是在TCP的发送端就采取了拥塞控制措施，但实际上网络并没有发生拥塞。
网络层的策略对TCP拥塞控制影响最大的就是路由器的分组丢弃策略。在最简单的情
况下，路由器的队列通常都按照“先进先出“FIFO(FirstInFirstOut)的规则处理到来的分
组。山千队列长度总是有限的，因此当队列已满时，以后再到达的所有分组（如果能够继•245•续排队，这些分组都将排在队列的尾部）将都被丢弃。这就叫作尾部丢弃策略(tail-droppolicy)。

**关键词**: 计算机网络 路由器 分组丢弃策略 FIFO 尾部丢弃策略 TCP拥塞控制


### 关键词提取 - 分块 24
路由器的尾部丢弃往往会导(cid:7175)一连串分组的丢失，这就使发送方出现超时重传，使TCP进入拥塞控制的慢开始状态，结果使TCP连接的发送方突然把数据的发送速率降低到很小的数值。更为严重的是，在网络中通常有很多的TCP连接（它们有不同的源点和终点），这些连接中的报文段通常是复用在网络层的IP数据报中传送的。在这种情况下，若发生了路由器中的尾部丢弃，就可(cid:7126)会同时影响到很多条TCP连接，结果使这许多TCP连接在同一时间突然都进入到慢开始状态。这在TCP的术语中称为全局同步(globalsynchronization)。
全局同步使得全网的通信量突然下降了很多，而在网络恢复正常后，其通信量又突然增大很多。

**关键词**: 路由器 尾部丢弃 分组丢失 TCP进入拥塞控制的慢开始状态 慢开始 TCP连接 报文段 IP数据报 全局同步


### 关键词提取 - 分块 25
全局同步使得全网的通信量突然下降了很多，而在网络恢复正常后，其通信量又突然增大很多。
为了避免发生网络中的全局同步现象，在1998年提出了主动队列管理AQM(ActiveQueueManagement)。所谓“主动”就是不要等到路由器的队列长度已经达到最大值时才不得不丢弃后面到达的分组。这样就太被动了。应当在队列长度达到某个值得警惕的数值时（即当网络拥塞有了某些拥塞征兆时），就主动丢弃到达的分组。这样就提醒了发送方放慢发送的速率，因而有可(cid:7126)使网络拥塞的程度减轻，甚(cid:7169)不出现网络拥塞。AQM可以有不同实现方法，其中曾流行多年的就是随机早期检测RED(RandomEarlyDetection)oRED还有几个不同的名称，如RandomEarlyDrop或RandomEarlyDiscard（随机早期丢弃）。
实现RED时需要使路由器维持两个参数，即队列长度最小门限和最大门限。当每一个分组到达时，RED就按照规定的算法先计算当前的平均队列长度。
(1)若平均队列长度小于最小门限，则把新到达的分组放入队列进行排队。

**关键词**: 全局同步 主动队列管理AQM 路由器 队列长度 网络拥塞 随机早期检测RED 随机早期丢弃 随机早期discard 最小门限 最大门限


### 关键词提取 - 分块 26
(1)若平均队列长度小于最小门限，则把新到达的分组放入队列进行排队。
(2)若平均队列长度超过最大门限，则把新到达的分组丢弃。
(3)若平均队列长度在最小门限和最大门限之间，则按照某一丢弃概率p把新到达的分组丢弃（这就体现了丢弃分组的随机性）。
由此可见，RED不是等到已经发生网络拥塞后才把所有在队列尾部的分组全部丢弃，而是在检测到网络拥塞的早期征兆时（即路由器的平均队列长度达到一定数值时），就以概率p丢弃个别的分组，让拥塞控制只在个别的TCP连接上进行，因而避免发生全局性的拥塞控制。
在RED的操作中，最难处理的就是丢弃概率p的选择，因为p并不是个常数。对每一个到达的分组，都必须计算丢弃概率p的数值。IETF曾经推荐在互(cid:7110)网中的路由器使用RED机制[RFC2309]，但多年的实践证明，
公布的RFC7567已经把过去的RFC2309列为“陈旧的RED的使用效果并不太理想。因此，在2015年

**关键词**: 计算机网络 队列长度 最小门限 最大门限 丢弃概率 RED机制 全局性的拥塞控制 互连网 路由器 RFC2309 RFC7567


### 关键词提取 - 分块 27
＂，并且不再推荐使用RED。对路由器进行主动队列管理AQM仍是必要的。AQM实际上就是对路由器中的分组排队进行智(cid:7126)管理，而不是简单地把队列的尾部丢弃。现在已经有几种不同的算法来代替旧的RED,但
都还在实验阶段。目前还没有一种算法(cid:7126)够成为IETF的标准，读者可注意这方面的进展。
5.9TCP的运输连接管理TCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释•246•

**关键词**: 计算机网络 路由器 主动队列管理(AQM) 分组排队 RED 算法 IETF TCP运输连接 运输连接

